{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from yolo3_one_file_to_detect_them_all import WeightReader,make_yolov3_model,decode_netout,correct_yolo_boxes,do_nms\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy,Precision,Recall\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from keras.optimizers import Adam\n",
    "from threading import Thread, Condition\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "900.0\n",
      "576.0\n",
      "428.0\n"
     ]
    }
   ],
   "source": [
    "# check the video frames\n",
    "video = cv2.VideoCapture('clip.mp4')\n",
    "print(str(video.get(cv2.CAP_PROP_FPS)))\n",
    "print(str(video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print(str(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print(str(video.get(cv2.CAP_PROP_FRAME_WIDTH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights and save to a model\n",
    "model = make_yolov3_model()                     # get a yolo model\n",
    "weight_reader = WeightReader('yolov3.weights')  # get the weights\n",
    "weight_reader.load_weights(model)               # load the weights\n",
    "model.save('Tiny_yolo.h5')                      # save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = {'Frame':[],\n",
    "        'Sedan':[],\n",
    "        'SUV':[],\n",
    "        'Total':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 654 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 225 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create train,test and validation sets\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('images/train',\n",
    "                                                 target_size=(416,416),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "validation_generator = validate_datagen.flow_from_directory(\n",
    "        'images/validation',\n",
    "        target_size=(416, 416),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('images/test',\n",
    "                                                 target_size=(416,416),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = MobileNet(weights='imagenet',include_top=False) # load MobileNet with weights from ImageNet without the last layer\n",
    "pretrained_model.trainable = False                                 # make the base model untrainable\n",
    "x = pretrained_model.output                                        # take the output layer\n",
    "x = GlobalAveragePooling2D()(x)                                    # add a pooling layer\n",
    "x = Dense(1024,activation='relu')(x)                               # add a dense layer\n",
    "x = Dense(1024,activation='relu')(x)                               # add a dense layer\n",
    "x = Dense(512,activation='relu')(x)                                # add a dense layer\n",
    "pred_layer = Dense(2,activation='softmax')(x)                      # add a softmax layer\n",
    "classification_model = Model(inputs=pretrained_model.input,outputs=pred_layer)  # initialise the model\n",
    "classification_model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy',Precision(),\n",
    "                       Recall()])                               # compile the model\n",
    "# Adam optimizer \n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "for layer in classification_model.layers[:20]:\n",
    "    layer.trainable=False                                       # set some layers as not trainable\n",
    "for layer in classification_model.layers[20:]:\n",
    "    layer.trainable=True                                        # set the rest of the layers as trainable           \n",
    "\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "history = classification_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator)\n",
    "classification_model.save('classification_model_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Frame number is 0\n",
      "Frame number is 1\n",
      "Frame number is 2\n",
      "Frame number is 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-153565265924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m \u001b[0mObjectDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindCars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;31m#o.start()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-153565265924>\u001b[0m in \u001b[0;36mfindCars\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcorrect_yolo_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;31m# suppress non-maximal boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mdo_nms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;31m# define the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"person\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bicycle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"car\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter\\RTI\\yolo3_one_file_to_detect_them_all.py\u001b[0m in \u001b[0;36mdo_nms\u001b[1;34m(boxes, nms_thresh)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m         \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \"\"\"\n\u001b[1;32m-> 1107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argsort'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load and prepare an image\n",
    "\n",
    "class ObjectDetector():\n",
    "    \n",
    "    def __init__(self,model=[]):\n",
    "        super(ObjectDetector, self).__init__()\n",
    "        self.model = load_model('Tiny_yolo.h5')                                   # load the tinyYolo model\n",
    "        self.classification_model = load_model('classification_model_latest.h5')\n",
    "        self.input_w, self.input_h = 416, 416\n",
    "        self.video = cv2.VideoCapture('clip.mp4')                      # get the input video\n",
    "        self.video_w = int(self.video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.video_h = int(self.video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        format_video = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        self.output_video = cv2.VideoWriter('output.mp4', format_video, 10, (self.video_w,self.video_h))\n",
    "    \n",
    "    def load_image_pixels(self, frame): \n",
    "        image = cv2.resize(frame,(self.input_w,self.input_h))\n",
    "        # make prediction\n",
    "        image = img_to_array(image)\n",
    "        # scale pixel values to [0, 1]\n",
    "        image = image.astype('float32')\n",
    "        image /= 255.0\n",
    "        # add a dimension so that we have one sample\n",
    "        image = expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "    def get_boxes(self,boxes, labels, thresh):\n",
    "        v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "        # enumerate all boxes\n",
    "        for box in boxes:\n",
    "            # enumerate all possible labels\n",
    "            for i in range(len(labels)):\n",
    "                # check if the threshold for this label is high enough\n",
    "                if box.classes[i] > thresh:\n",
    "                    v_boxes.append(box)\n",
    "                    v_labels.append(labels[i])\n",
    "                    v_scores.append(box.classes[i]*100)\n",
    "                    # don't break, many labels may trigger for one box            \n",
    "        return v_boxes, v_labels, v_scores\n",
    "\n",
    "    def draw_boxes(self,image, box, labels, obj_thresh):\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            #print(labels[i])\n",
    "\n",
    "        if len(label) > 0:\n",
    "            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3) # draw a rectangle\n",
    "            cv2.putText(image,                                                           # write text\n",
    "                        label, \n",
    "                        (box.xmin, box.ymin - 13), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1e-3 * image.shape[0], \n",
    "                        (0,255,0), 2)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def classify(self,frame,box):\n",
    "        #print('inside classify')\n",
    "        #time.sleep(random.random())\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        crop_image = frame[y1:y1+height,x1:x1+width]\n",
    "        try:\n",
    "           crop_image = cv2.resize(crop_image,(416,416))\n",
    "        except:\n",
    "           #print('return') \n",
    "           return frame\n",
    "        crop_image = img_to_array(crop_image)\n",
    "        # scale pixel values to [0, 1]\n",
    "        crop_image = crop_image.astype('float32')\n",
    "        crop_image /= 255.0\n",
    "        # add a dimension so that we have one sample\n",
    "        #pyplot.imshow(crop_image)\n",
    "        crop_image = expand_dims(crop_image, 0)\n",
    "        y_ = np.argmax(self.classification_model.predict(crop_image))\n",
    "        if(train_generator.class_indices['sedan'] == y_):\n",
    "            label = ['Sedan']\n",
    "        else:\n",
    "            label = ['SUV']\n",
    "        image = self.draw_boxes(frame,box,label,0.6)\n",
    "        return image\n",
    "            \n",
    "    \n",
    "    def findCars(self):\n",
    "        global queue\n",
    "        dataFrame['Frame'] = []\n",
    "        for i in range(900):\n",
    "            print('Frame number is',i)    # for debug\n",
    "            frameCount = dataFrame['Frame']\n",
    "            dataFrame['Total'].append(0)\n",
    "            if len(frameCount) > 0:\n",
    "                count = frameCount[-1]\n",
    "                frameCount.append(count+1)\n",
    "                #print(frameCount)\n",
    "            else:\n",
    "                frameCount.insert(0,1)\n",
    "                #print(frameCount)\n",
    "            retVal,frame = self.video.read()\n",
    "            # define the anchors\n",
    "            anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "            # define the probability threshold for detected objects\n",
    "            class_threshold = 0.6\n",
    "            boxes = list()\n",
    "            image_h, image_w, _ = frame.shape \n",
    "            image = self.load_image_pixels(frame)\n",
    "            yhat = self.model.predict(image)\n",
    "\n",
    "            for j in range(len(yhat)):\n",
    "               # decode the output of the network\n",
    "               boxes += decode_netout(yhat[j][0], anchors[j], class_threshold, self.input_h, self.input_w)\n",
    "               # correct the sizes of the bounding boxes for the shape of the image\n",
    "            correct_yolo_boxes(boxes, image_h, image_w, self.input_h, self.input_w)\n",
    "            # suppress non-maximal boxes\n",
    "            do_nms(boxes, 0.5)\n",
    "            # define the labels\n",
    "            labels = [\"person\", \"bicycle\", \"car\"]\n",
    "            # get the details of the detected objects\n",
    "            v_boxes, v_labels, v_scores = self.get_boxes(boxes, labels, class_threshold)\n",
    "            # summarize what we found\n",
    "            #print(v_boxes, v_labels, v_scores)\n",
    "            #print('boxes count',len(v_boxes))\n",
    "            total = 0\n",
    "            #print('boxes is',v_boxes)\n",
    "            for k in range(len(v_boxes)):\n",
    "                box = v_boxes[k]\n",
    "                #print('inside k')\n",
    "                total += 1\n",
    "                dataFrame['Total'][i] = total\n",
    "                frame = self.classify(frame,box)\n",
    "            self.output_video.write(frame)\n",
    "        self.output_video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "                        \n",
    "ObjectDetector().findCars()\n",
    "#o.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.save('classification_model_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DuckDuckGoImages as ddg\n",
    "ddg.download('suv',folder='images/SUV',max_urls=100)    # api for downloading images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv2.resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(classification_model.outputs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "millis = int(round(time.time()))\n",
    "print(millis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
